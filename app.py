import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from wordcloud import WordCloud
from matplotlib.colors import LinearSegmentedColormap
from mpl_toolkits.mplot3d import Axes3D
from matplotlib.lines import Line2D
import os
import gdown # Ajout pour le t√©l√©chargement depuis Google Drive

# --- √âTAPE 1 : Chargement des donn√©es depuis Google Drive ---
# NOTE : Ce script va t√©l√©charger le fichier Parquet si il n'est pas trouv√© localement.
GDRIVE_FILE_ID = "1ilv6IxVUT34ZmQkWR-hzjp9PMLvs2byW"
LOCAL_DATA_FILE = "instacart_sample_1m.parquet" # Nom du fichier qui sera sauvegard√© localement

# On utilise un "d√©corateur" de Streamlit. @st.cache_data dit √† l'application :
# "Ex√©cute cette fonction une seule fois. Si on la rappelle avec les m√™mes arguments,
# ne la recalcule pas, utilise directement le r√©sultat que tu as mis en cache (en m√©moire)."
# C'est tr√®s efficace pour ne pas re-t√©l√©charger et re-lire le fichier √† chaque interaction de l'utilisateur.
@st.cache_data(ttl=24*3600)
def load_data():
    """
    T√©l√©charge les donn√©es depuis Google Drive si elles ne sont pas disponibles localement,
    puis les charge dans un DataFrame Pandas.
    """
    # On v√©rifie d'abord si le fichier de donn√©es existe d√©j√† sur le disque o√π l'application tourne.
    if not os.path.exists(LOCAL_DATA_FILE):
        try:
            # On construit l'URL de t√©l√©chargement direct √† partir de l'ID du fichier Google Drive.
            url = f'https://drive.google.com/uc?id={GDRIVE_FILE_ID}'
            # On utilise la biblioth√®que gdown pour t√©l√©charger le fichier.
            gdown.download(url, LOCAL_DATA_FILE, quiet=False)
            st.success("T√©l√©chargement termin√©.")
        except Exception as e:
            # Si le t√©l√©chargement √©choue, on affiche un message d'erreur clair.
            st.error("ERREUR : Impossible de t√©l√©charger le fichier depuis Google Drive.")
            st.error(f"V√©rifiez que le lien de partage est bien public ('Tous les utilisateurs disposant du lien').")
            st.error(f"D√©tails de l'erreur: {e}")
            # On retourne un DataFrame vide pour que l'application ne plante pas.
            return pd.DataFrame()
            
    try:
        # Une fois que le fichier est bien pr√©sent localement, on l'ouvre avec pandas.
        # Le format Parquet est tr√®s optimis√©, c'est bien plus rapide √† lire qu'un CSV.
        df = pd.read_parquet(LOCAL_DATA_FILE)
        # On s'assure que la colonne 'Cluster' est bien de type 'category'.
        # C'est une bonne pratique qui aide pandas et les biblioth√®ques de graphiques √† mieux la g√©rer.
        df['Cluster'] = df['Cluster'].astype('category')
        return df
    except Exception as e:
        # Si la lecture du fichier √©choue (fichier corrompu, etc.), on affiche une erreur.
        st.error(f"Erreur de lecture du fichier Parquet : {e}")
        return pd.DataFrame()

# --- Initialisation de l'application ---
# On configure la page pour qu'elle utilise toute la largeur de l'√©cran.
st.set_page_config(layout="wide")

# --- Introduction de l'application ---
# st.title et st.markdown sont les commandes de base pour √©crire du texte dans Streamlit.
st.title("üöÄ DUDA - Analyse de Cohortes v1")
st.markdown('''
### par Alexandre Cameron BORGES & Alioune DIOP

Nous avons con√ßu ce MVP d'application pour explorer des donn√©es clients et aider √† prendre de meilleures d√©cisions marketing. C'est une premi√®re version (MVP) que nous avons d√©velopp√©e dans le cadre de notre formation au **DU Data Analytics de l'Universit√© Panth√©on Sorbonne**.

**Quel est l'objectif ?**
Dans un monde o√π le suivi des utilisateurs devient plus compliqu√© (fin des cookies tiers), il est essentiel de bien comprendre ses propres clients. Notre outil utilise les donn√©es internes d'une entreprise pour :
- **Identifier les produits et rayons qui marchent le mieux**.
- **Comprendre le comportement d'achat des clients** √† travers des analyses comme le mod√®le RFM (R√©cence, Fr√©quence, Montant).
- **Segmenter la client√®le en groupes (clusters)** pour mieux cibler les actions marketing.

Pour cette d√©monstration, nous utilisons un jeu de donn√©es public d'Instacart provenant de Kaggle, qui contient 1 million de commandes.
''')

# On appelle notre fonction pour charger les donn√©es. Gr√¢ce au cache,
# cela ne sera r√©ellement ex√©cut√© qu'une seule fois au d√©marrage.
df = load_data()
# Si le DataFrame est vide (√† cause d'une erreur de chargement), on arr√™te l'ex√©cution du script.
if df.empty:
    st.stop()

# --- Pr√©traitement & filtres dans la barre lat√©rale ---
# st.sidebar permet de placer des √©l√©ments dans la barre lat√©rale gauche.
st.sidebar.header("PARAM√àTRES D'ANALYSE")

jours = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']
# On v√©rifie que la colonne 'order_dow' existe bien avant de l'utiliser.
if 'order_dow' in df.columns:
    # On cr√©e une nouvelle colonne avec les noms des jours en toutes lettres pour que ce soit plus lisible.
    # On utilise pd.Categorical pour s'assurer que les jours restent dans le bon ordre.
    df['order_dow_name'] = pd.Categorical(df['order_dow'].map({i: jours[i] for i in range(7)}), categories=jours, ordered=True)
else:
    st.error("La colonne 'order_dow' est manquante dans les donn√©es.")
    st.stop()

# On cr√©e les widgets interactifs dans la barre lat√©rale.
# st.sidebar.multiselect permet de choisir plusieurs options dans une liste.
selected_days = st.sidebar.multiselect(
    "Jours de la semaine", options=jours, default=jours
)
# st.sidebar.slider cr√©e un curseur pour s√©lectionner une plage de valeurs.
h_min, h_max = st.sidebar.slider(
    "Heure de la journ√©e", int(df['order_hour_of_day'].min()), int(df['order_hour_of_day'].max()), (0, 23)
)
aisle_options = sorted(df['aisle'].unique().tolist())
cluster_options = sorted(df['Cluster'].unique().tolist())

selected_aisles = st.sidebar.multiselect(
    "Rayons (Aisles)", options=aisle_options, default=aisle_options
)
selected_clusters = st.sidebar.multiselect(
    "Clusters RFM", options=cluster_options, default=cluster_options
)

# Le c≈ìur de l'interactivit√© est ici.
# On filtre le DataFrame principal en fonction des choix de l'utilisateur dans la sidebar.
# Le DataFrame 'filtered' ne contient que les lignes qui correspondent √† tous les crit√®res.
filtered = df[
    (df['order_dow_name'].isin(selected_days)) &
    (df['order_hour_of_day'].between(h_min, h_max)) &
    (df['aisle'].isin(selected_aisles)) &
    (df['Cluster'].isin(selected_clusters))
]

st.markdown("Nombre de commandes correspondant √† nos filtres :")
# st.metric est un afficheur sp√©cial pour les chiffres cl√©s.
st.metric("Lignes s√©lectionn√©es", f"{len(filtered):,}")

# --- KPI globaux : prix moyen par produit, panier moyen, LTV moyenne ---
col1, col2, col3 = st.columns(3)

# 1) Prix moyen par produit
avg_price_product = df['price'].mean()

# 2) Panier moyen par commande
order_totals_all = df.groupby('order_id')['price'].sum()
avg_order_value_all = order_totals_all.mean()

# 3) LTV moyenne par client
user_totals_all = df.groupby('user_id')['price'].sum()
avg_ltv_all = user_totals_all.mean()

# Affichage
col1.metric("Prix moyen par produit", f"{avg_price_product:.2f} ‚Ç¨")
col2.metric("Panier moyen par commande", f"{avg_order_value_all:.2f} ‚Ç¨")
col3.metric("D√©pense moyenne par client (LTV)", f"{avg_ltv_all:.2f} ‚Ç¨")




# --- Section des Visualisations ---

st.header("üõí Analyse des Ventes : Produits et Rayons")

# --- GRAPHIQUES PRODUITS AVEC PIE CHART ---
st.subheader("Quels sont nos produits vedettes ?")
st.markdown("Ici, on regarde les produits qui sont les plus vendus, √† la fois en quantit√© et en chiffre d'affaires. Cela nous aide √† identifier les produits stars.")
if not filtered.empty:
    # On calcule les top 12 produits en quantit√© vendue.
    top_qty_prod = filtered.groupby('product_name').size().nlargest(12)
    # On calcule les top 12 produits en chiffre d'affaires.
    top_rev_prod = filtered.groupby('product_name')['price'].sum().nlargest(12)
    # On fusionne les deux listes pour avoir une vision compl√®te des produits importants.
    prods_union = pd.Index(top_qty_prod.index).union(top_rev_prod.index)
    # On recalcule les m√©triques (quantit√© et CA) uniquement pour cette liste de produits.
    df_prod = (
        filtered.groupby('product_name')
        .agg(total_qty=('order_id', 'count'), total_rev=('price', 'sum'))
        .loc[prods_union]
        .sort_values('total_qty', ascending=False)
    )
    # On cr√©e une figure Matplotlib avec 2 graphiques (subplots) c√¥te √† c√¥te.
    fig_prod, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10), gridspec_kw={'width_ratios': [2, 1]})
    
    y_prod = list(range(len(df_prod)))
    # On dessine le premier graphique √† barres (quantit√©).
    bars1 = ax1.barh([i - 0.2 for i in y_prod], df_prod['total_qty'], height=0.4, color='steelblue', label='Quantit√© vendue')
    ax1.set_yticks(y_prod); ax1.set_yticklabels(df_prod.index, fontsize=9); ax1.set_xlabel('Quantit√© vendue'); ax1.invert_yaxis()
    # ax1.twiny() cr√©e un deuxi√®me axe des abscisses (X) qui partage le m√™me axe des ordonn√©es (Y).
    # C'est l'astuce pour afficher deux mesures diff√©rentes (quantit√© et CA) sur le m√™me graphique.
    ax_tw = ax1.twiny()
    # On dessine le second graphique √† barres (chiffre d'affaires).
    bars2 = ax_tw.barh([i + 0.2 for i in y_prod], df_prod['total_rev'], height=0.4, color='darkorange', label="Chiffre d'affaires (‚Ç¨)")
    ax_tw.set_xlabel("Chiffre d'affaires (‚Ç¨)")
    ax1.legend(handles=[bars1, bars2], labels=[h.get_label() for h in [bars1, bars2]], loc='lower right')
    ax1.set_title("Top produits : Quantit√© vs Chiffre d'affaires")

    # On dessine le second graphique : le diagramme circulaire (camembert).
    ordered_prod_rev = df_prod['total_rev'].sort_values(ascending=False)
    ax2.pie(
        ordered_prod_rev.values, autopct='%1.1f%%', labels=ordered_prod_rev.index,
        startangle=90, wedgeprops={'edgecolor': 'white'}
    )
    ax2.axis('equal'); ax2.set_title("R√©partition du CA par produit\n(Top produits)")
    
    # On affiche la figure compl√®te dans Streamlit.
    plt.tight_layout()
    st.pyplot(fig_prod)

    # --- MODIFICATION POUR LES BALLONS ---
    # On utilise st.session_state pour s'assurer que les ballons n'apparaissent qu'une seule fois par session.
    # st.session_state.get('balloons_shown') v√©rifie si la cl√© 'balloons_shown' existe.
    if not st.session_state.get('balloons_shown'):
        # Si elle n'existe pas, on lance les ballons.
        st.balloons()
        # Et on cr√©e imm√©diatement la cl√© en la mettant √† True pour ne pas que √ßa se reproduise.
        st.session_state.balloons_shown = True
    # --- FIN DE LA MODIFICATION ---

else:
    st.warning("Aucune donn√©e de produit √† afficher avec les filtres actuels.")


# --- GRAPHIQUES RAYONS AVEC PIE CHART ---
st.subheader("Quels sont les rayons les plus populaires ?")
st.markdown("De la m√™me mani√®re que pour les produits, on analyse ici les rayons pour voir lesquels attirent le plus de clients et g√©n√®rent le plus de revenus.")
if not filtered.empty:
    # La logique est identique √† celle des produits, mais en groupant par 'aisle' (rayon).
    top_qty_aisle = filtered.groupby('aisle').size().nlargest(12)
    top_rev_aisle = filtered.groupby('aisle')['price'].sum().nlargest(10)
    aisles_union = pd.Index(top_qty_aisle.index).union(top_rev_aisle.index)
    df_aisle = (
        filtered.groupby('aisle')
        .agg(total_qty=('order_id', 'count'), total_rev=('price', 'sum'))
        .loc[aisles_union]
        .sort_values('total_qty', ascending=False)
    )
    fig_aisle, (ax1_a, ax2_a) = plt.subplots(1, 2, figsize=(18, 8), gridspec_kw={'width_ratios': [2, 1]})

    y_aisle = list(range(len(df_aisle)))
    bars1_a = ax1_a.barh([i - 0.2 for i in y_aisle], df_aisle['total_qty'], height=0.4, color='steelblue', label='Quantit√© vendue')
    ax1_a.set_yticks(y_aisle); ax1_a.set_yticklabels(df_aisle.index); ax1_a.set_xlabel('Quantit√© vendue'); ax1_a.invert_yaxis()
    ax2b_a = ax1_a.twiny()
    bars2_a = ax2b_a.barh([i + 0.2 for i in y_aisle], df_aisle['total_rev'], height=0.4, color='darkorange', label="Chiffre d'affaires (‚Ç¨)")
    ax2b_a.set_xlabel("Chiffre d'affaires (‚Ç¨)")
    ax1_a.legend(handles=[bars1_a, bars2_a], labels=[h.get_label() for h in [bars1_a, bars2_a]], loc='lower right')
    ax1_a.set_title("Top rayons : Quantit√© vs CA")

    ordered_aisle_rev = df_aisle['total_rev'].sort_values(ascending=False)
    ax2_a.pie(
        ordered_aisle_rev.values, labels=ordered_aisle_rev.index, autopct='%1.1f%%',
        startangle=90, wedgeprops={'edgecolor': 'white'}
    )
    ax2_a.axis('equal'); ax2_a.set_title("R√©partition du CA par rayon\n(Top rayons)")
    
    plt.tight_layout()
    st.pyplot(fig_aisle)
else:
    st.warning("Aucune donn√©e de rayon √† afficher avec les filtres actuels.")


# --- ANALYSE TEMPORELLE ---
st.header("üóìÔ∏è Analyse Temporelle : Quand les clients commandent-ils ?")
st.markdown("Cette section nous permet de visualiser les habitudes d'achat au fil de la semaine et de la journ√©e, pour savoir quand nos clients sont les plus actifs.")
if not filtered.empty:
    # On calcule les donn√©es n√©cessaires : le nombre de commandes par heure et par jour.
    top_hours = filtered.groupby('order_hour_of_day').size()
    top_days = filtered.groupby('order_dow_name').size()
    # Pour la heatmap, on doit cr√©er une "matrice" o√π les lignes sont les jours et les colonnes les heures.
    # .unstack() est la fonction pandas qui permet de faire cette transformation.
    sales_matrix = filtered.groupby(['order_dow_name', 'order_hour_of_day']).size().unstack(fill_value=0).reindex(jours)
    sales_matrix_k = sales_matrix / 1000 # On divise par 1000 pour un affichage plus lisible.

    # On cr√©e une figure avec 3 graphiques.
    fig_temp, axes = plt.subplots(1, 3, figsize=(20, 6), gridspec_kw={'width_ratios': [1, 1, 1.5]})

    # Graphique 1 : Barres pour les jours.
    sns.barplot(x=top_days.index, y=top_days.values, palette='Greens', ax=axes[0])
    axes[0].set_title("Commandes par jour")
    axes[0].set_xlabel("Jour de la semaine")
    axes[0].set_ylabel("Nombre de produits command√©s")
    axes[0].tick_params(axis='x', rotation=45)

    # Graphique 2 : Barres pour les heures.
    sns.barplot(x=top_hours.index, y=top_hours.values, palette='Greens', ax=axes[1])
    axes[1].set_title("Commandes par heure")
    axes[1].set_xlabel("Heure de la journ√©e")
    axes[1].set_ylabel("Nombre de produits command√©s")
    axes[1].tick_params(axis='x', rotation=45)

    # Graphique 3 : La heatmap (carte de chaleur).
    cmap_wg = LinearSegmentedColormap.from_list('RedGreen', ['#fdecec', '#2b8a3e'])
    sns.heatmap(
        sales_matrix_k, annot=True, fmt='.1f', cmap=cmap_wg, linewidths=0.5, linecolor='white',
        annot_kws={'fontsize': 8}, cbar_kws={'label': 'Commandes (en milliers)'}, ax=axes[2]
    )
    axes[2].set_title("Fr√©quentation par jour et heure")
    axes[2].set_xlabel("Heure de la journ√©e")
    axes[2].set_ylabel("Jour de la semaine")
    
    plt.tight_layout()
    st.pyplot(fig_temp)
else:
    st.warning("Aucune donn√©e pour l'analyse temporelle avec les filtres actuels.")


st.header("üë• Analyse des Clients par Clusters (Mod√®le RFM)")
st.markdown("Le mod√®le RFM (R√©cence, Fr√©quence, Montant) est une technique marketing puissante pour comprendre le comportement des clients. Nous l'utilisons pour classer les clients en diff√©rents groupes (clusters), comme les 'champions', les 'clients √† risque', etc. Cela nous permet d'adapter nos strat√©gies de communication pour chaque groupe.")

# --- PAIRPLOT ---
st.subheader("Vue d'ensemble des relations entre les indicateurs RFM")
st.info("‚ÑπÔ∏è Pour que l'affichage reste rapide, ce graphique est calcul√© sur un √©chantillon al√©atoire des donn√©es s√©lectionn√©es.")
if not filtered.empty:
    # On prend un petit √©chantillon des donn√©es (5000 lignes) car ce graphique est tr√®s lent √† calculer.
    SAMPLE_SIZE_PAIRPLOT = 5000
    # .reset_index(drop=True) est une s√©curit√© pour √©viter des bugs d'index avec pandas.
    df_for_pairplot = filtered.sample(n=min(len(filtered), SAMPLE_SIZE_PAIRPLOT), random_state=42).reset_index(drop=True)
    
    # sns.pairplot cr√©e une matrice de graphiques pour visualiser les relations entre chaque paire de variables.
    g = sns.pairplot(
        df_for_pairplot, vars=["Recency", "Frequency", "Monetary"], hue="Cluster", palette="Set2"
    )
    g.fig.suptitle("Pairplot des variables RFM par Cluster", y=1.03)
    st.pyplot(g)
else:
    st.warning("Aucune donn√©e √† afficher pour le pairplot.")


# --- GRAPHIQUES 3D ---
st.subheader("Exploration 3D des segments de clients")
# On utilise st.columns pour afficher les deux graphiques 3D c√¥te √† c√¥te.
col3d_1, col3d_2 = st.columns(2)

with col3d_1:
    st.markdown("##### Vue d'ensemble statique")
    st.info("‚ÑπÔ∏è Cette vue est une image fixe, calcul√©e sur un √©chantillon pour plus de rapidit√©.")
    if not filtered.empty:
        # On prend un √©chantillon de 10 000 lignes pour ce graphique.
        SAMPLE_SIZE_STATIC_3D = 10000
        df_for_plot_static = filtered.sample(n=min(len(filtered), SAMPLE_SIZE_STATIC_3D), random_state=42).reset_index(drop=True)
        
        # On cr√©e un dictionnaire qui associe chaque num√©ro de cluster √† une couleur.
        unique_clusters = sorted(df_for_plot_static['Cluster'].unique())
        palette_static = sns.color_palette("Set2", len(unique_clusters))
        color_dict = dict(zip(unique_clusters, palette_static))
        
        fig_static = plt.figure(figsize=(8, 6))
        ax_static = fig_static.add_subplot(111, projection='3d')
        
        # On dessine les points pour chaque cluster un par un, dans une boucle.
        # C'est une m√©thode plus robuste qui √©vite certains bugs de pandas.
        for cluster, color in color_dict.items():
            cluster_data = df_for_plot_static[df_for_plot_static['Cluster'] == cluster]
            ax_static.scatter(
                cluster_data["Recency"], 
                cluster_data["Frequency"], 
                cluster_data["Monetary"],
                c=[color],
                s=20, 
                alpha=0.6,
                label=f'Cluster {cluster}' # Le 'label' est important pour cr√©er la l√©gende automatiquement.
            )

        ax_static.set_xlabel("Recency")
        ax_static.set_ylabel("Frequency")
        ax_static.set_zlabel("Monetary")
        ax_static.legend(title="Cluster", fontsize='small')
        st.pyplot(fig_static)

with col3d_2:
    st.markdown("##### Vue interactive pour l'exploration")
    st.info("‚ÑπÔ∏è Vous pouvez tourner, zoomer et survoler les points pour voir les d√©tails. Ce graphique utilise aussi un √©chantillon.")
    if not filtered.empty:
        # On peut se permettre un √©chantillon plus grand (50 000) car Plotly est tr√®s optimis√© pour le web.
        SAMPLE_SIZE_INTERACTIVE_3D = 50000
        df_for_plot_interactive = filtered.sample(n=min(len(filtered), SAMPLE_SIZE_INTERACTIVE_3D), random_state=42).reset_index(drop=True)

        # Pour √™tre s√ªr que les couleurs sont les m√™mes que sur les autres graphiques,
        # on cr√©e une "map" de couleurs explicite.
        all_clusters = sorted(df['Cluster'].unique())
        hex_colors = sns.color_palette("Set2", len(all_clusters)).as_hex()
        color_discrete_map = {cluster: color for cluster, color in zip(all_clusters, hex_colors)}
        
        # On cr√©e le graphique 3D avec Plotly Express, c'est tr√®s direct.
        fig_interactive = px.scatter_3d(
            df_for_plot_interactive, 
            x='Recency', y='Frequency', z='Monetary', 
            color='Cluster',
            color_discrete_map=color_discrete_map, # On passe notre map de couleurs ici.
            title=f"Clusters RFM ({len(df_for_plot_interactive):,} points)"
        )
        
        # Quelques ajustements pour rendre le graphique plus joli.
        fig_interactive.update_traces(marker=dict(size=3, opacity=0.7))
        fig_interactive.update_layout(margin=dict(l=0, r=0, b=0, t=40), legend=dict(orientation="h", yanchor="bottom", y=0.01))
        st.plotly_chart(fig_interactive, use_container_width=True)

# --- AJOUT DU TABLEAU RECAPITULATIF ---
st.header("üí° Synth√®se par Segment")
st.markdown("Ce tableau r√©sume les caract√©ristiques de chaque segment de client√®le et propose des pistes d'actions concr√®tes pour chacun.")

st.markdown("""
| Cluster | Nom du Segment | R√©cence (Moyenne) | Fr√©quence (Moyenne) | Montant (Moyen) | Nb de Clients | Interpr√©tations | Priorit√©s |
|:---:|:---|:---:|:---:|:---:|:---:|:---|:---|
| 2 | **üå± Nouveaux Clients / Prometteurs** | 4 | 6 | 177.90‚Ç¨ | 104,382 | Ont achet√© tr√®s r√©cemment mais peu souvent. Potentiel de croissance. | **C'est votre futur.** Mettez en place des processus solides pour transformer ces nouveaux acheteurs en clients r√©guliers et, √† terme, en champions. |
| 0 | **üë§ Clients Occasionnels** | 10 | 15 | 483.90‚Ç¨ | 58,169 | Ach√®tent de temps en temps, sans grande fr√©quence ni d√©pense. | **Maintenez le contact** via des actions automatis√©es et √† faible co√ªt. Ils constituent une base stable qui peut r√©agir aux offres de masse. |
| 3 | **‚ö†Ô∏è Clients √† Risque / Sur le d√©part** | 15 | 32 | 1,162.30‚Ç¨ | 33,628 | Clients de valeur qui n'ont pas achet√© depuis longtemps. Risque de churn. | **Agissez MAINTENANT** pour retenir ces clients de valeur. C'est souvent plus rentable de retenir un client que d'en acqu√©rir un nouveau. |
| 1 | **üèÜ Champions / Meilleurs Clients** | 13 | 64 | 2,829.40‚Ç¨ | 10,030 | Tr√®s fid√®les et d√©pensent beaucoup. Le c≈ìur de votre chiffre d'affaires. | **Chouchoutez ce groupe.** Ils financent la croissance. Assurez-vous qu'ils restent heureux et fid√®les. |
""")
# --- FIN DE L'AJOUT ---

# --- WORDCLOUD OPTIONNEL ---
st.sidebar.markdown("---")
st.sidebar.subheader("Bonus : Analyse de Texte")
# st.sidebar.file_uploader permet √† l'utilisateur de charger son propre fichier.
article_file = st.sidebar.file_uploader("Uploader un fichier .txt", type=["txt"])
if article_file:
    st.header("‚òÅÔ∏è Nuage de mots √† partir de votre texte")
    try:
        # On lit le contenu du fichier texte et on g√©n√®re le nuage de mots.
        text = article_file.read().decode('utf-8')
        wc = WordCloud(width=800, height=400, background_color='white', collocations=False).generate(text)
        fig_wc, ax_wc = plt.subplots(figsize=(12,6))
        ax_wc.imshow(wc, interpolation='bilinear')
        ax_wc.axis('off')
        st.pyplot(fig_wc)
    except Exception as e:
        st.error(f"Erreur lors de la g√©n√©ration du WordCloud : {e}")

# --- Footer ---
st.markdown("---")
st.caption("Application r√©alis√©e par Alexandre Cameron BORGES & Alioune DIOP pour le DU Panth√©on Sorbonne Data Analytics.")
